<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · SimpleChains.jl</title><meta name="title" content="Home · SimpleChains.jl"/><meta property="og:title" content="Home · SimpleChains.jl"/><meta property="twitter:title" content="Home · SimpleChains.jl"/><meta name="description" content="Documentation for SimpleChains.jl."/><meta property="og:description" content="Documentation for SimpleChains.jl."/><meta property="twitter:description" content="Documentation for SimpleChains.jl."/><meta property="og:url" content="https://PumasAI.github.io/SimpleChains.jl/"/><meta property="twitter:url" content="https://PumasAI.github.io/SimpleChains.jl/"/><link rel="canonical" href="https://PumasAI.github.io/SimpleChains.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>SimpleChains.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="examples/smallmlp/">Small Multi-Layer Perceptron</a></li><li><a class="tocitem" href="examples/mnist/">MNIST - Convolutions</a></li><li><a class="tocitem" href="examples/custom_loss_layer/">Adding a custom loss layer</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/PumasAI/SimpleChains.jl/blob/main/docs/src/index.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="SimpleChains"><a class="docs-heading-anchor" href="#SimpleChains">SimpleChains</a><a id="SimpleChains-1"></a><a class="docs-heading-anchor-permalink" href="#SimpleChains" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/PumasAI/SimpleChains.jl">SimpleChains</a>.</p><ul><li><a href="#SimpleChains.ADAM"><code>SimpleChains.ADAM</code></a></li><li><a href="#SimpleChains.AbsoluteLoss"><code>SimpleChains.AbsoluteLoss</code></a></li><li><a href="#SimpleChains.AbstractPenalty"><code>SimpleChains.AbstractPenalty</code></a></li><li><a href="#SimpleChains.Activation"><code>SimpleChains.Activation</code></a></li><li><a href="#SimpleChains.Conv"><code>SimpleChains.Conv</code></a></li><li><a href="#SimpleChains.Dropout"><code>SimpleChains.Dropout</code></a></li><li><a href="#SimpleChains.Flatten"><code>SimpleChains.Flatten</code></a></li><li><a href="#SimpleChains.FrontLastPenalty"><code>SimpleChains.FrontLastPenalty</code></a></li><li><a href="#SimpleChains.L1Penalty"><code>SimpleChains.L1Penalty</code></a></li><li><a href="#SimpleChains.L2Penalty"><code>SimpleChains.L2Penalty</code></a></li><li><a href="#SimpleChains.LogitCrossEntropyLoss"><code>SimpleChains.LogitCrossEntropyLoss</code></a></li><li><a href="#SimpleChains.MaxPool"><code>SimpleChains.MaxPool</code></a></li><li><a href="#SimpleChains.SimpleChain"><code>SimpleChains.SimpleChain</code></a></li><li><a href="#SimpleChains.SquaredLoss"><code>SimpleChains.SquaredLoss</code></a></li><li><a href="#SimpleChains.TurboDense"><code>SimpleChains.TurboDense</code></a></li><li><a href="#Base.front-Tuple{SimpleChain}"><code>Base.front</code></a></li><li><a href="#SimpleChains.add_loss-Tuple{SimpleChain, SimpleChains.AbstractLoss}"><code>SimpleChains.add_loss</code></a></li><li><a href="#SimpleChains.alloc_threaded_grad-Union{Tuple{SimpleChain}, Tuple{T}, Tuple{SimpleChain, Union{Nothing, SimpleChains.InputDimUnknown, Tuple{Vararg{Union{Integer, Static.StaticInt}}}}}, Tuple{SimpleChain, Union{Nothing, SimpleChains.InputDimUnknown, Tuple{Vararg{Union{Integer, Static.StaticInt}}}}, Type{T}}} where T"><code>SimpleChains.alloc_threaded_grad</code></a></li><li><a href="#SimpleChains.biases"><code>SimpleChains.biases</code></a></li><li><a href="#SimpleChains.init_params-Union{Tuple{T}, Tuple{SimpleChain, Type{T}}} where T"><code>SimpleChains.init_params</code></a></li><li><a href="#SimpleChains.init_params!"><code>SimpleChains.init_params!</code></a></li><li><a href="#SimpleChains.numparam-Tuple{TurboDense, Tuple}"><code>SimpleChains.numparam</code></a></li><li><a href="#SimpleChains.params"><code>SimpleChains.params</code></a></li><li><a href="#SimpleChains.pullback_arg!-NTuple{6, Any}"><code>SimpleChains.pullback_arg!</code></a></li><li><a href="#SimpleChains.train_batched!-Tuple{Union{Nothing, AbstractMatrix, AbstractVector}, AbstractVector, Union{SimpleChains.AbstractPenalty{&lt;:SimpleChain}, SimpleChain}, Any, SimpleChains.AbstractOptimizer, Any}"><code>SimpleChains.train_batched!</code></a></li><li><a href="#SimpleChains.train_unbatched!-Tuple{Any, AbstractVector, Union{SimpleChains.AbstractPenalty{&lt;:SimpleChain}, SimpleChain}, Any, SimpleChains.AbstractOptimizer, Any}"><code>SimpleChains.train_unbatched!</code></a></li><li><a href="#SimpleChains.valgrad!-Tuple{Ptr{UInt8}, Any, SimpleChain, Any, Any}"><code>SimpleChains.valgrad!</code></a></li><li><a href="#SimpleChains.weights"><code>SimpleChains.weights</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.ADAM" href="#SimpleChains.ADAM"><code>SimpleChains.ADAM</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ADAM(η = 0.001, β = (0.9, 0.999))</code></pre><p>ADAM optimizer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/optimize.jl#L4-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.AbsoluteLoss" href="#SimpleChains.AbsoluteLoss"><code>SimpleChains.AbsoluteLoss</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AbsoluteLoss</code></pre><p>Calculates mean absolute loss of the target.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/loss.jl#L110-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.AbstractPenalty" href="#SimpleChains.AbstractPenalty"><code>SimpleChains.AbstractPenalty</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AbstractPenalty</code></pre><p>The <code>AbstractPenalty</code> interface requires supporting the following methods:</p><ol><li><code>getchain(::AbstractPenalty)::SimpleChain</code> returns a <code>SimpleChain</code> if it is carrying one.</li><li><code>apply_penalty(::AbstractPenalty, params)::Number</code> returns the penalty</li><li><code>apply_penalty!(grad, ::AbstractPenalty, params)::Number</code> returns the penalty and updates <code>grad</code> to add the gradient.</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L33-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.Activation" href="#SimpleChains.Activation"><code>SimpleChains.Activation</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Activation(activation)</code></pre><p>Applies <code>activation</code> function elementwise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/activation.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.Conv" href="#SimpleChains.Conv"><code>SimpleChains.Conv</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Conv(activation, dims::Tuple{Vararg{Integer}}, outputdim::Integer)</code></pre><p>Performs a convolution with <code>dims</code> and maps it to <code>outputdim</code> output channels, then adds a bias (one per <code>outputdim</code>) and applies <code>activation</code> elementwise.</p><p>E.g., <code>Conv(relu, (5, 5), 16)</code> performs a <code>5 × 5</code> convolution, and maps the input channels to 16 output channels, before adding a bias and applying <code>relu</code>.</p><p>Randomly initializing weights using the (Xavier) Glorot uniform distribution. The bias is zero-initialized.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/conv.jl#L750-L761">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.Dropout" href="#SimpleChains.Dropout"><code>SimpleChains.Dropout</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Dropout(p) # 0 &lt; p &lt; 1</code></pre><p>Dropout layer.</p><p>When evaluated without gradients, it multiplies inputs by <code>(1 - p)</code>. When evaluated with gradients, it randomly zeros <code>p</code> proportion of inputs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/dropout.jl#L3-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.Flatten" href="#SimpleChains.Flatten"><code>SimpleChains.Flatten</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Flatten{N}()</code></pre><p>Flattens the first <code>N</code> dimensions. E.g.,</p><pre><code class="language-julia hljs">julia&gt; Flatten{2}()(rand(2, 3, 4))
6×4 Matrix{Float64}:
 0.0609115  0.597285  0.279899  0.888223
 0.0667422  0.315741  0.351003  0.805629
 0.678297   0.350817  0.984215  0.399418
 0.125801   0.566696  0.96873   0.57744
 0.331961   0.350742  0.59598   0.741998
 0.26345    0.144635  0.076433  0.330475</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/flatten.jl#L2-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.FrontLastPenalty" href="#SimpleChains.FrontLastPenalty"><code>SimpleChains.FrontLastPenalty</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">FrontLastPenalty(SimpleChain, frontpen(λ₁...), lastpen(λ₂...))</code></pre><p>Applies <code>frontpen</code> to all but the last layer, applying <code>lastpen</code> to the last layer instead. &quot;Last layer&quot; here ignores the loss function, i.e. if the last element of the chain is a loss layer, the then <code>lastpen</code> applies to the layer preceding this.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/penalty.jl#L166-L172">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.L1Penalty" href="#SimpleChains.L1Penalty"><code>SimpleChains.L1Penalty</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">L1Penalty(λ)</code></pre><p>Applies a L1 penalty of <code>λ</code> to parameters, i.e. penalizing by their absolute value.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/penalty.jl#L84-L88">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.L2Penalty" href="#SimpleChains.L2Penalty"><code>SimpleChains.L2Penalty</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">L2Penalty(λ)</code></pre><p>Applies a L2 penalty of <code>λ</code> to parameters, i.e. penalizing by their squares.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/penalty.jl#L125-L129">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.LogitCrossEntropyLoss" href="#SimpleChains.LogitCrossEntropyLoss"><code>SimpleChains.LogitCrossEntropyLoss</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LogitCrossEntropyLoss</code></pre><p>Calculates mean logit cross-entropy loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/loss.jl#L165-L169">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.MaxPool" href="#SimpleChains.MaxPool"><code>SimpleChains.MaxPool</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MaxPool(dims::Tuple{Vararg{Integer}}</code></pre><p>Calculates the maximum of pools of size <code>dims</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/maxpool.jl#L2-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.SimpleChain" href="#SimpleChains.SimpleChain"><code>SimpleChains.SimpleChain</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SimpleChain([inputdim::Union{Integer,Tuple{Vararg{Integer}}, ] layers)</code></pre><p>Construct a SimpleChain. Optional <code>inputdim</code> argument allows <code>SimpleChains</code> to check the size of inputs. Making these <code>static</code> will allow <code>SimpleChains</code> to infer size and loop bounds at compile time. Batch size generally should not be included in the <code>inputdim</code>. If <code>inputdim</code> is not specified, some methods, e.g. <code>init_params</code>, will require passing the size as an additional argument, because the number of parameters may be a function of the input size (e.g., for a <code>TurboDense</code> layer).</p><p>The <code>layers</code> argument holds various <code>SimpleChains</code> layers, e.g. <code>TurboDense</code>, <code>Conv</code>, <code>Activation</code>, <code>Flatten</code>, <code>Dropout</code>, or <code>MaxPool</code>. It may optionally terminate in an <code>AbstractLoss</code> layer.</p><p>These objects are callable, e.g.</p><pre><code class="language-julia hljs">c = SimpleChain(...);
p = SimpleChains.init_params(c);
c(X, p) # X are the independent variables, and `p` the parameter vector.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L5-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.SquaredLoss" href="#SimpleChains.SquaredLoss"><code>SimpleChains.SquaredLoss</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SquaredLoss(target)</code></pre><p>Calculates half of mean squared loss of the target.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/loss.jl#L56-L60">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.TurboDense" href="#SimpleChains.TurboDense"><code>SimpleChains.TurboDense</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">TurboDense{B=true}(activation, outputdim::Integer)</code></pre><p>Linear (dense) layer.</p><ul><li><code>B</code> specifies whether the layer includes a bias term.</li><li>The <code>activation</code> function is applied elementwise to the result.</li><li><code>outputdim</code> indicates how many dimensions the input is mapped to.</li></ul><p>Randomly initializing weights using the (Xavier) Glorot normal distribution. The bias is zero-initialized.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/dense.jl#L2-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.front-Tuple{SimpleChain}" href="#Base.front-Tuple{SimpleChain}"><code>Base.front</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Base.front(c::SimpleChain)</code></pre><p>Useful for popping off a loss layer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L85-L89">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.add_loss-Tuple{SimpleChain, SimpleChains.AbstractLoss}" href="#SimpleChains.add_loss-Tuple{SimpleChain, SimpleChains.AbstractLoss}"><code>SimpleChains.add_loss</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">add_loss(chn, l::AbstractLoss)</code></pre><p>Add the loss function <code>l</code> to the simple chain. The loss function should hold the target you&#39;re trying to fit.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/loss.jl#L4-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.alloc_threaded_grad-Union{Tuple{SimpleChain}, Tuple{T}, Tuple{SimpleChain, Union{Nothing, SimpleChains.InputDimUnknown, Tuple{Vararg{Union{Integer, Static.StaticInt}}}}}, Tuple{SimpleChain, Union{Nothing, SimpleChains.InputDimUnknown, Tuple{Vararg{Union{Integer, Static.StaticInt}}}}, Type{T}}} where T" href="#SimpleChains.alloc_threaded_grad-Union{Tuple{SimpleChain}, Tuple{T}, Tuple{SimpleChain, Union{Nothing, SimpleChains.InputDimUnknown, Tuple{Vararg{Union{Integer, Static.StaticInt}}}}}, Tuple{SimpleChain, Union{Nothing, SimpleChains.InputDimUnknown, Tuple{Vararg{Union{Integer, Static.StaticInt}}}}, Type{T}}} where T"><code>SimpleChains.alloc_threaded_grad</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">alloc_threaded_grad(chn, id = nothing, ::Type{T} = Float32; numthreads = min(Threads.nthreads(), SimpleChains.num_cores())</code></pre><p>Returns a preallocated array for writing gradients, for use with <code>train_batched</code> and <code>train_unbatched</code>. If Julia was started with multiple threads, returns a matrix with one column per thread, so they may accumulate gradients in parallel.</p><p>Note that the memory is aligned to avoid false sharing.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/utils.jl#L229-L237">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.biases" href="#SimpleChains.biases"><code>SimpleChains.biases</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">biases(sc::SimpleChain, p::AbstractVector, inputdim = nothing)</code></pre><p>Returns a tuple of the biases of the SimpleChain <code>sc</code>, as a view of the parameter vector <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/utils.jl#L289-L293">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.init_params!" href="#SimpleChains.init_params!"><code>SimpleChains.init_params!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SimpleChains.init_params!(chn, p, id = nothing)</code></pre><p>Randomly initializes parameter vector <code>p</code> with input dim <code>id</code>. Input dim does not need to be specified if these were provided to the chain object itself. See the documentation of the individual layers to see how they are initialized, but it is generally via (Xavier) Glorot uniform or normal distributions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L455-L460">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.init_params-Union{Tuple{T}, Tuple{SimpleChain, Type{T}}} where T" href="#SimpleChains.init_params-Union{Tuple{T}, Tuple{SimpleChain, Type{T}}} where T"><code>SimpleChains.init_params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SimpleChains.init_params(chn[, id = nothing][, ::Type{T} = Float32])</code></pre><p>Creates a parameter vector of element type <code>T</code> with size matching that by <code>id</code> (argument not required if provided to the <code>chain</code> object itself). See the documentation of the individual layers to see how they are initialized, but it is generally via (Xavier) Glorot uniform or normal distributions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L495-L500">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.numparam-Tuple{TurboDense, Tuple}" href="#SimpleChains.numparam-Tuple{TurboDense, Tuple}"><code>SimpleChains.numparam</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">numparam(d::Layer, inputdim::Tuple)</code></pre><p>Returns a <code>Tuple{Int,S}</code>. The first element is the number of parameters required by the layer given an argument of size <code>inputdim</code>. The second argument is the size of the object returned by the layer, which can be fed into <code>numparam</code> of the following layer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/dense.jl#L46-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.params" href="#SimpleChains.params"><code>SimpleChains.params</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">params(sc::SimpleChain, p::AbstractVector, inputdim = nothing)</code></pre><p>Returns a tuple of the parameters of the SimpleChain <code>sc</code>, as a view of the parameter vector <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/utils.jl#L259-L263">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.pullback_arg!-NTuple{6, Any}" href="#SimpleChains.pullback_arg!-NTuple{6, Any}"><code>SimpleChains.pullback_arg!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">pullback_arg!(dest, layer, C̄, A, p, pu, pu2)</code></pre><p>Computes the pullback of <code>layer</code> with respect to <code>A</code> and <code>C̄</code>, storing the result in <code>dest</code>.</p><pre><code class="nohighlight hljs">pullback_arg!(layer, C̄, A, p, pu, pu2)</code></pre><p>Computes the pullback of <code>layer</code> with respect to <code>A</code> and <code>C̄</code>, storing the result in <code>A</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L630-L638">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.train_batched!-Tuple{Union{Nothing, AbstractMatrix, AbstractVector}, AbstractVector, Union{SimpleChains.AbstractPenalty{&lt;:SimpleChain}, SimpleChain}, Any, SimpleChains.AbstractOptimizer, Any}" href="#SimpleChains.train_batched!-Tuple{Union{Nothing, AbstractMatrix, AbstractVector}, AbstractVector, Union{SimpleChains.AbstractPenalty{&lt;:SimpleChain}, SimpleChain}, Any, SimpleChains.AbstractOptimizer, Any}"><code>SimpleChains.train_batched!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">train_batched!(g::AbstractVecOrMat, p, chn, X, opt, iters; batchsize = nothing)</code></pre><p>Train while batching arguments.</p><p>Arguments:</p><ul><li><code>g</code> pre-allocated gradient buffer. Can be allocated with <code>similar(p)</code> (if you want to run single threaded), or <code>alloc_threaded_grad(chn, size(X))</code> (<code>size(X)</code> argument is only necessary if the input dimension was not specified when constructing the chain). If a matrix, the number of columns gives how many threads to use. Do not use more threads than batch size would allow.</li><li><code>p</code> is the parameter vector. It is updated inplace. It should be pre-initialized, e.g. with <code>init_params</code>/<code>init_params!</code>. This is to allow calling <code>train_unbatched!</code> several times to train in increments.</li><li><code>chn</code> is the <code>SimpleChain</code>. It must include a loss (see <code>SimpleChains.add_loss</code>) containing the target information (dependent variables) you&#39;re trying to fit.</li><li><code>X</code> the training data input argument (independent variables).</li><li><code>opt</code> is the optimizer. Currently, only <code>SimpleChains.ADAM</code> is supported.</li><li><code>iters</code>, how many iterations to train for.</li><li><code>batchsize</code> keyword argument: the size of the batches to use. If <code>batchsize = nothing</code>, it&#39;ll try to do a half-decent job of picking the batch size for you. However, this is not well optimized at the moment.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/optimize.jl#L650-L664">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.train_unbatched!-Tuple{Any, AbstractVector, Union{SimpleChains.AbstractPenalty{&lt;:SimpleChain}, SimpleChain}, Any, SimpleChains.AbstractOptimizer, Any}" href="#SimpleChains.train_unbatched!-Tuple{Any, AbstractVector, Union{SimpleChains.AbstractPenalty{&lt;:SimpleChain}, SimpleChain}, Any, SimpleChains.AbstractOptimizer, Any}"><code>SimpleChains.train_unbatched!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">train_unbatched!([g::AbstractVecOrMat, ]p, chn, X, opt, iters)</code></pre><p>Train without batching inputs.</p><p>Arguments:</p><ul><li><code>g</code> pre-allocated gradient buffer. Can be allocated with <code>similar(p)</code> (if you want to run single threaded), or <code>alloc_threaded_grad(chn, size(X))</code> (<code>size(X)</code> argument is only necessary if the input dimension was not specified when constructing the chain). If a matrix, the number of columns gives how many threads to use. Do not use more threads than batch size would allow. This argument is optional. If excluded, it will run multithreaded (assuming you started Julia with multiple threads).</li><li><code>p</code> is the parameter vector. It is updated inplace. It should be pre-initialized, e.g. with <code>init_params</code>/<code>init_params!</code>. This is to allow calling <code>train_unbatched!</code> several times to train in increments.</li><li><code>chn</code> is the <code>SimpleChain</code>. It must include a loss (see <code>SimpleChains.add_loss</code>) containing the target information (dependent variables) you&#39;re trying to fit.</li><li><code>X</code> the training data input argument (independent variables).</li><li><code>opt</code> is the optimizer. Currently, only <code>SimpleChains.ADAM</code> is supported.</li><li><code>iters</code>, how many iterations to train for.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/optimize.jl#L395-L408">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.valgrad!-Tuple{Ptr{UInt8}, Any, SimpleChain, Any, Any}" href="#SimpleChains.valgrad!-Tuple{Ptr{UInt8}, Any, SimpleChain, Any, Any}"><code>SimpleChains.valgrad!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">valgrad!(g, c::SimpleChain, arg, params)</code></pre><p><code>g</code> can be either an <code>AbstractVector</code> with the same size as <code>params</code>, or a <code>Tuple{A,G}</code>. If <code>g</code> is a tuple, the first element is the gradient with respect to <code>arg</code>, and should either be <code>nothing</code> (for not taking this gradient) or have the same <code>size</code> as arg. The second element is the gradient with respect to <code>params</code>, and should likewise either be <code>nothing</code> or have the same size as <code>params</code>.</p><p>Allowed destruction:</p><pre><code class="nohighlight hljs">valgrad_layer!</code></pre><p>Accepts return of previous layer (<code>B</code>) and returns an ouput <code>C</code>. If an internal layer, allowed to destroy <code>B</code> (e.g. dropout layer).</p><pre><code class="nohighlight hljs">pullback!</code></pre><p>Accepts adjoint of its return (<code>C̄</code>). It is allowed to destroy this. It is also allowed to destroy the previous layer&#39;s return <code>B</code> to produce <code>B̄</code> (the <code>C̄</code> it receives). Thus, the pullback is not allowed to depend on <code>C</code>, as it may have been destroyed in producing <code>C̄</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/simple_chain.jl#L524-L545">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SimpleChains.weights" href="#SimpleChains.weights"><code>SimpleChains.weights</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">weights(sc::SimpleChain, p::AbstractVector, inputdim = nothing)</code></pre><p>Returns a tuple of the weights (parameters other than biases) of the SimpleChain <code>sc</code>, as a view of the parameter vector <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/PumasAI/SimpleChains.jl/blob/0e575a610ac96f5b7f0d7525d481327b4310e1e8/src/utils.jl#L274-L278">source</a></section></article><ul><li><a href="examples/smallmlp/#Small-Multi-Layer-Perceptron">Small Multi-Layer Perceptron</a></li><li><a href="examples/mnist/#MNIST-Convolutions">MNIST - Convolutions</a></li><li><a href="examples/custom_loss_layer/#Adding-a-custom-loss-layer">Adding a custom loss layer</a></li><li class="no-marker"><ul><li><a href="examples/custom_loss_layer/#Mathematical-background-for-a-Binary-Cross-Entropy-Loss">Mathematical background for a Binary Cross Entropy Loss</a></li><li><a href="examples/custom_loss_layer/#Implementing-a-custom-loss-type">Implementing a custom loss type</a></li></ul></li></ul></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="examples/smallmlp/">Small Multi-Layer Perceptron »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.6.0 on <span class="colophon-date" title="Monday 2 September 2024 09:27">Monday 2 September 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
