<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>MNIST - Convolutions · SimpleChains.jl</title><meta name="title" content="MNIST - Convolutions · SimpleChains.jl"/><meta property="og:title" content="MNIST - Convolutions · SimpleChains.jl"/><meta property="twitter:title" content="MNIST - Convolutions · SimpleChains.jl"/><meta name="description" content="Documentation for SimpleChains.jl."/><meta property="og:description" content="Documentation for SimpleChains.jl."/><meta property="twitter:description" content="Documentation for SimpleChains.jl."/><meta property="og:url" content="https://PumasAI.github.io/SimpleChains.jl/examples/mnist/"/><meta property="twitter:url" content="https://PumasAI.github.io/SimpleChains.jl/examples/mnist/"/><link rel="canonical" href="https://PumasAI.github.io/SimpleChains.jl/examples/mnist/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SimpleChains.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../smallmlp/">Small Multi-Layer Perceptron</a></li><li class="is-active"><a class="tocitem" href>MNIST - Convolutions</a></li><li><a class="tocitem" href="../custom_loss_layer/">Adding a custom loss layer</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>MNIST - Convolutions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>MNIST - Convolutions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/PumasAI/SimpleChains.jl/blob/main/docs/src/examples/mnist.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MNIST-Convolutions"><a class="docs-heading-anchor" href="#MNIST-Convolutions">MNIST - Convolutions</a><a id="MNIST-Convolutions-1"></a><a class="docs-heading-anchor-permalink" href="#MNIST-Convolutions" title="Permalink"></a></h1><p>First, we load the data using <a href="https://github.com/JuliaML/MLDatasets.jl">MLDatasets.jl</a>:</p><pre><code class="language-julia hljs">using MLDatasets
xtrain3, ytrain0 = MLDatasets.MNIST.traindata(Float32);
xtest3, ytest0 = MLDatasets.MNIST.testdata(Float32);
size(xtest3)
# (28, 28, 60000)
extrema(ytrain0) # digits, 0,...,9
# (0, 9)</code></pre><p>The covariate data (<code>x</code>) were named <code>3</code> as these are three-dimensional arrays, containing the height x width x number of images. The training data are vectors indicating the digit.</p><pre><code class="language-julia hljs">xtrain4 = reshape(xtrain3, 28, 28, 1, :);
xtest4 = reshape(xtest3, 28, 28, 1, :);
ytrain1 = UInt32.(ytrain0 .+ 1);
ytest1 = UInt32.(ytest0 .+ 1);</code></pre><p>SimpleChains&#39; convolutional layers expect that we have a channels-in dimension, so we shape the images to be four dimensional It also currently defaults to 1-based indexing for its categories, so we shift all categories by 1.</p><p>We now define our model, LeNet5:</p><pre><code class="language-julia hljs">using SimpleChains

lenet = SimpleChain(
  (static(28), static(28), static(1)),
  SimpleChains.Conv(SimpleChains.relu, (5, 5), 6),
  SimpleChains.MaxPool(2, 2),
  SimpleChains.Conv(SimpleChains.relu, (5, 5), 16),
  SimpleChains.MaxPool(2, 2),
  Flatten(3),
  TurboDense(SimpleChains.relu, 120),
  TurboDense(SimpleChains.relu, 84),
  TurboDense(identity, 10),
)

lenetloss = SimpleChains.add_loss(lenet, LogitCrossEntropyLoss(ytrain1));</code></pre><p>We define the inputs as being statically sized <code>(28,28,1)</code> images. Specifying the input sizes allows these to be checked. Making them static, which we can do either in our simple chain, or by adding static sizing to the images themselves using a package like <a href="https://github.com/JuliaSIMD/StrideArrays.jl">StrideArrays.jl</a> or <a href="https://github.com/JuliaArrays/HybridArrays.jl">HybridArrays.jl</a>. These packages are recommended for allowing you to mix dynamic and static sizes; the batch size should probably be left dynamic, as you&#39;re unlikely to want to specialize code generation on this, given that it is likely to vary, increasing compile times while being unlikely to improve runtimes.</p><p>In <code>SimpleChains</code>, the parameters are not a part of the model, but live as a separate vector that you can pass around to optimizers of your choosing. If you specified the input size, you create a random initial parameter vector corresponding to the model:</p><pre><code class="language-julia hljs">@time p = SimpleChains.init_params(lenet);</code></pre><p>The convolutional layers are initialized with a Glorot (Xavier) uniform distribution, while the dense layers are initialized with a Glorot (Xaviar) normal distribution. Biases are initialized to zero. Because the number of parameters can be a function of the input size, these must be provided if you didn&#39;t specify input dimension. For example:</p><pre><code class="language-julia hljs">@time p = SimpleChains.init_params(lenet, size(xtrain4));</code></pre><p>To allow training to use multiple threads, you can create a gradient matrix, with a number of rows equal to the length of the parameter vector <code>p</code>, and one column per thread. For example:</p><pre><code class="language-julia hljs">estimated_num_cores = (Sys.CPU_THREADS ÷ ((Sys.ARCH === :x86_64) + 1));
G = SimpleChains.alloc_threaded_grad(lenetloss);</code></pre><p>Here, we&#39;re estimating that the number of physical cores is half the number of threads on an <code>x86_64</code> system, which is true for most – but not all!!! – of them. Otherwise, we&#39;re assuming it is equal to the number of threads. This is of course also likely to be wrong, e.g. recent Power CPUs may have 4 or even 8 threads per core. You may wish to change this, or use <a href="https://github.com/JuliaParallel/Hwloc.jl">Hwloc.jl</a> for an accurate number.</p><p>Now that this is all said and done, we can train for <code>10</code> epochs using the <code>ADAM</code> optimizer with a learning rate of <code>3e-4</code>, and then assess the accuracy and loss of both the training and test data:</p><pre><code class="language-julia hljs">@time SimpleChains.train_batched!(G, p, lenetloss, xtrain4, SimpleChains.ADAM(3e-4), 10);
SimpleChains.accuracy_and_loss(lenetloss, xtrain4, p)
SimpleChains.accuracy_and_loss(lenetloss, xtest4, ytest1, p)</code></pre><p>Training for an extra 10 epochs should be fast on most systems. Performance is currently known to be poor on the M1 (PRs welcome, otherwise we&#39;ll look into this eventually), but should be  good/great on systems with AVX2/AVX512:</p><pre><code class="language-julia hljs">@time SimpleChains.train_batched!(G, p, lenetloss, xtrain4, SimpleChains.ADAM(3e-4), 10);
SimpleChains.accuracy_and_loss(lenetloss, xtrain4, p)
SimpleChains.accuracy_and_loss(lenetloss, xtest4, ytest1, p)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../smallmlp/">« Small Multi-Layer Perceptron</a><a class="docs-footer-nextpage" href="../custom_loss_layer/">Adding a custom loss layer »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 1 September 2025 14:40">Monday 1 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
